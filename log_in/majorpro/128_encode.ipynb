{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import all the required files and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "import cv2\n",
    "import copy\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from numpy import genfromtxt\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import the necessary modules (i.e. weights,models etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fr_utils import *\n",
    "from inception_blocks_v2 import *\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.set_printoptions(threshold=np.nan)\n",
    "FRmodel = faceRecoModel(input_shape=(3, 96, 96))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# triplet loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
    "    \"\"\"\n",
    "    Implementation of the triplet loss as defined by formula (3)\n",
    "    \n",
    "    Arguments:\n",
    "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
    "    y_pred -- python list containing three objects:\n",
    "            anchor -- the encodings for the anchor images, of shape (None, 128)\n",
    "            positive -- the encodings for the positive images, of shape (None, 128)\n",
    "            negative -- the encodings for the negative images, of shape (None, 128)\n",
    "    \n",
    "    Returns:\n",
    "    loss -- real number, value of the loss\n",
    "    \"\"\"\n",
    "    \n",
    "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "\n",
    "    ### START CODE HERE ### (â‰ˆ 4 lines)\n",
    "# Step 1: Compute the (encoding) distance between the anchor and the positive, you will need to sum over axis=-1\n",
    "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,positive)))\n",
    "# Step 2: Compute the (encoding) distance between the anchor and the negative, you will need to sum over axis=-1\n",
    "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,negative)))\n",
    "    # Step 3: subtract the two previous distances and add alpha.\n",
    "    basic_loss = pos_dist-neg_dist+alpha\n",
    "    # Step 4: Take the maximum of basic_loss and 0.0. Sum over the training examples.\n",
    "    loss = tf.reduce_sum(tf.math.maximum(basic_loss,0))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loading the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRmodel.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])\n",
    "load_weights_from_FaceNet(FRmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read the 1st image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1=\"_dataset/400.jpg\"         # _dataset folder contain cropped faces of students\n",
    "#image1=\"taken_dataset/400.jpg\"\n",
    "image = cv2.imread(image1)\n",
    "#gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "row,col,chan = image.shape\n",
    "# resize the original image as per requirement \n",
    "\n",
    "reimage=cv2.resize(image,(96,96),interpolation =cv2.INTER_AREA )\n",
    "for n in range (3):\n",
    "    # initialze an array color required for padding\n",
    "    coll = image[0, 0, n]   #coll = gray[row - 1, col - 1]\n",
    "    color = [int(coll), int(coll), int(coll)]\n",
    "    \n",
    "    if row>col:\n",
    "        teimage =reimage[:,:,n]\n",
    "        row, col = teimage.shape\n",
    "        left = right = ((96 - col)/2)\n",
    "        sqimage = cv2.copyMakeBorder(teimage, 0, 0, int(left), int(right), cv2.BORDER_CONSTANT, value=color)\n",
    "        row, col = sqimage.shape\n",
    "        if(row != col):\n",
    "            sqimage = cv2.copyMakeBorder(sqimage, 0, 0, 0, 1, cv2.BORDER_CONSTANT, value=color)\n",
    "       # overwrite the subsequent channel of original image\n",
    "        reimage[:,:,n]=sqimage\n",
    "        \n",
    "    else:\n",
    "       # reimage = image_resize(image[:,:,n], width=96)\n",
    "        teimage=reimage[:,:,n]\n",
    "        row, col = teimage.shape\n",
    "        top = bottom = (96 - row)/2\n",
    "        sqimage = cv2.copyMakeBorder(teimage, int(top), int(bottom), 0, 0, cv2.BORDER_CONSTANT, value=color)\n",
    "        row, col = sqimage.shape\n",
    "        if (row != col):\n",
    "            sqimage = cv2.copyMakeBorder(sqimage, 0, 1, 0, 0, cv2.BORDER_CONSTANT, value=color)\n",
    "     # overwrite the subsequent channel of original image\n",
    "        reimage[:,:,n]=sqimage\n",
    "# save the processed image in the system\n",
    "cv2.imwrite(\"C:/Users/Lenovo/Deep_learning/TanuJ_sir/padded.jpg\", reimage)\n",
    "# create the encoding of 1st image using siamese network\n",
    "arr = img_to_encoding(\"C:/Users/Lenovo/Deep_learning/TanuJ_sir/padded.jpg\", FRmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read the second image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "image2=\"eg/10.jpg\"         #in eg folder I store images of different persons\n",
    "\n",
    "immage = cv2.imread(image2)\n",
    "#gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "row,col,chan = immage.shape\n",
    "\n",
    "reimage2=cv2.resize(immage,(96,96),interpolation =cv2.INTER_AREA)   \n",
    "for n in range (3):\n",
    "    # initialze an array color required for padding\n",
    "    coll = immage[0, 0, n]   #coll = gray[row - 1, col - 1]\n",
    "    color = [int(coll), int(coll), int(coll)]\n",
    "    \n",
    "    if row>col:\n",
    "        teimage2 =reimage2[:,:,n]\n",
    "        row, col = teimage2.shape\n",
    "        left = right = ((96 - col)/2)\n",
    "        sqimage = cv2.copyMakeBorder(teimage2, 0, 0, int(left), int(right), cv2.BORDER_CONSTANT, value=color)\n",
    "        row, col = sqimage.shape\n",
    "        if(row != col):\n",
    "            sqimage = cv2.copyMakeBorder(sqimage, 0, 0, 0, 1, cv2.BORDER_CONSTANT, value=color)\n",
    "       # overwrite the subsequent channel of original image\n",
    "        reimage2[:,:,n]=sqimage\n",
    "        \n",
    "    else:\n",
    "       # reimage = image_resize(image[:,:,n], width=96)\n",
    "        teimage2=reimage2[:,:,n]\n",
    "        row, col = teimage2.shape\n",
    "        top = bottom = (96 - row)/2\n",
    "        sqimage = cv2.copyMakeBorder(teimage2, int(top), int(bottom), 0, 0, cv2.BORDER_CONSTANT, value=color)\n",
    "        row, col = sqimage.shape\n",
    "        if (row != col):\n",
    "            sqimage = cv2.copyMakeBorder(sqimage, 0, 1, 0, 0, cv2.BORDER_CONSTANT, value=color)\n",
    "            #k\n",
    "     # overwrite the subsequent channel of original image\n",
    "        reimage2[:,:,n]=sqimage\n",
    "# save the processed image in the system\n",
    "cv2.imwrite(\"C:/Users/Lenovo/Deep_learning/TanuJ_sir/padded2.jpg\",reimage2)\n",
    "arr2 = img_to_encoding(\"C:/Users/Lenovo/Deep_learning/TanuJ_sir/padded2.jpg\", FRmodel)\n",
    "arr2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### find the distance between two different images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0466303\n"
     ]
    }
   ],
   "source": [
    "diff=np.linalg.norm((arr-arr2))\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### run this blocks to save padded images from dataset inthe directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize counter to count total no of images inthe dataset\n",
    "count=0\n",
    "\n",
    "for i in os.listdir('_dataset'): \n",
    "    count=count+1\n",
    "    #image1=i\n",
    "    image = cv2.imread(os.path.join('_dataset',i))\n",
    "    #gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    #reimage=padding_image(image)\n",
    "    row,col,chan = image.shape\n",
    "    # resize the original image as per requirement \n",
    "\n",
    "\n",
    "    reimage=cv2.resize(image,(96,96),interpolation =cv2.INTER_AREA )\n",
    "    for n in range (3):\n",
    "        # initialze an array color required for padding\n",
    "        coll = image[0, 0, n]   #coll = gray[row - 1, col - 1]\n",
    "        color = [int(coll), int(coll), int(coll)]\n",
    "    \n",
    "        if row>col:\n",
    "            teimage =reimage[:,:,n]\n",
    "            row, col = teimage.shape\n",
    "            left = right = ((96 - col)/2)\n",
    "            sqimage = cv2.copyMakeBorder(teimage, 0, 0, int(left), int(right), cv2.BORDER_CONSTANT, value=color)\n",
    "            row, col = sqimage.shape\n",
    "            if(row != col):\n",
    "                sqimage = cv2.copyMakeBorder(sqimage, 0, 0, 0, 1, cv2.BORDER_CONSTANT, value=color)\n",
    "       # overwrite the subsequent channel of original image\n",
    "            reimage[:,:,n]=sqimage\n",
    "        \n",
    "        else:\n",
    "       # reimage = image_resize(image[:,:,n], width=96)\n",
    "            teimage=reimage[:,:,n]\n",
    "            row, col = teimage.shape\n",
    "            top = bottom = (96 - row)/2\n",
    "            sqimage = cv2.copyMakeBorder(teimage, int(top), int(bottom), 0, 0, cv2.BORDER_CONSTANT, value=color)\n",
    "            row, col = sqimage.shape\n",
    "            if (row != col):\n",
    "                sqimage = cv2.copyMakeBorder(sqimage, 0, 1, 0, 0, cv2.BORDER_CONSTANT, value=color)\n",
    "     # overwrite the subsequent channel of original image\n",
    "            reimage[:,:,n]=sqimage\n",
    "        \n",
    "         # save the processed image in the new folder named embedding\n",
    "        cv2.imwrite(\"C:/Users/Lenovo/Deep_learning/TanuJ_sir/embedding/\"+str(i)+\".jpg\",reimage)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### find the encoding of all the images in embedded directory and then take average of all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the list to store the encoding of all the images in dataset\n",
    "z=[]\n",
    "#run a loop through all the images in embedding folder to find their separate encodings\n",
    "for i in os.listdir('embedding'):\n",
    "    arr3=img_to_encoding(os.path.join('embedding',i), FRmodel)\n",
    "    # append encoding of individual images in list\n",
    "    z.append(arr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the list into numpy array\n",
    "zr=np.array(z)\n",
    "#find the sum of all encoding element wise\n",
    "z_sum=np.sum(zr,axis=0)\n",
    "#find the average\n",
    "z_mean=z_sum/count\n",
    "#z_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39778063\n"
     ]
    }
   ],
   "source": [
    "d=np.linalg.norm((z_mean-arr))\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f=dist_image(arr,arr3)\n",
    "#print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
